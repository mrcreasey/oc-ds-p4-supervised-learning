{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anticipez les besoins en consommation électrique de bâtiments\n",
    "\n",
    "- **Projet 4 du parcours « Data Scientist » d’OpenClassrooms**\n",
    "- **Mark Creasey**\n",
    "\n",
    "## Partie 1 : Nettoyage et analyse exploratoire des données\n",
    "\n",
    "<img width=\"200\" src=\"https://user.oc-static.com/upload/2019/02/24/15510245026714_Seattle_logo_landscape_blue-black.png\" alt=\"Logo seattle\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compréhension du problème\n",
    "\n",
    "## 1.1 Mission\n",
    "\n",
    "À partir des [relevés déjà réalisés en 2015 et 2016](https://www.kaggle.com/city-of-seattle/sea-building-energy-benchmarking#2015-building-energy-benchmarking.csv) :\n",
    "\n",
    "- **prédire les émissions de CO2** et la **consommation totale d’énergie** de bâtiments commerciales en Seattle pour lesquels elles n’ont pas encore été mesurées, basé sur les données déclaratives du permis d'exploitation commerciale (taille et usage des bâtiments, mention de travaux récents, date de construction…).\n",
    "\n",
    "- **évaluer l’intérêt de l’[ENERGY STAR Score](https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/interpret-your-results/what) pour la prédiction d’émissions**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1.1 Quelles variables pour prédire les consommations / emissions CO2 ?\n",
    "\n",
    "Il faut prédire les targets uniquement avec les données disponibles sur le permis d'exploitation commerciale :\n",
    "\n",
    "- on ne peut pas utiliser les relevés de consommation d'électricité, de gaz, etc comme paramètres des prévisions.\n",
    "- on peut utiliser type d'usage, surface, nombre d'étages, moyenne de chauffage, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1.2 Quels bâtiments à inclure dans les prévisions ?\n",
    "\n",
    "Il faut prédire les targets uniquement pour les bâtiments commerciaux.\n",
    "\n",
    "Donc, il faut éliminer les bâtiments residential, si possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Requirements : Bibliothèques utilisées dans ce notebook\n",
    "\n",
    "- voir [`requirements.txt`](./requirements.txt) pour les versions des bibliothèques testées avec ce notebook\n",
    "\n",
    "### 1.2.1 Import des bibliothèques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Liste des versions des bibliothèques utilisées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versions des bibliothèques utilisées:\n",
      "json==2.0.9; numpy==1.21.5; pandas==1.1.5; seaborn==0.11.2; scipy==1.7.3\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "python_version()\n",
    "print('versions des bibliothèques utilisées:')\n",
    "print('; '.join(f'{m.__name__}=={m.__version__}' for m in globals(\n",
    ").values() if getattr(m, '__version__', None)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Configuration défauts d'affichage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)  # pour afficher toutes les colonnes\n",
    "pd.set_option('display.max_rows', 10)  # pour afficher max 10 lignes\n",
    "pd.set_option('display.max_colwidth', 800)  # pour afficher toutes la text\n",
    "# pd.set_option('display.precision', 2)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"white\", context=\"notebook\")\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.set_palette(\"tab20\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Des fonctions utilitaires\n",
    "\n",
    "### 1.3.1 Enregistrement des graphiques\n",
    "\n",
    "Pour enregistrer les graphiques, define **`SAVE_IMAGES = True`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_IMAGES = True\n",
    "IMAGE_FOLDER = './images'\n",
    "if not os.path.exists(IMAGE_FOLDER):\n",
    "    os.makedirs(IMAGE_FOLDER)\n",
    "\n",
    "\n",
    "def to_png(fig_name=None):\n",
    "    \"\"\"\n",
    "    Enregistre l'image dans un fichier,\n",
    "    il faut appeler avant plt.show() pour pouvoir ajuster la taille de l'image\n",
    "    avec bbox_inches=tight pour être sûr d'inclure le titre / legend entier.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_title():\n",
    "        if plt.gcf()._suptitle is None:  # noqa\n",
    "            return plt.gca().get_title()\n",
    "        else:\n",
    "            return plt.gcf()._suptitle.get_text()  # noqa\n",
    "\n",
    "    if SAVE_IMAGES:\n",
    "        if fig_name is None:\n",
    "            fig_name = get_title()\n",
    "        elif len(fig_name) < 9:\n",
    "            fig_name = f'{fig_name}_{get_title()}'\n",
    "        fig_name = fig_name.replace(' ', '_').replace(\n",
    "            ':', '-').replace('.', '-').replace('/', '_')\n",
    "        print(f'\"{fig_name}.png\"')\n",
    "        plt.gcf().savefig(\n",
    "            f'{IMAGE_FOLDER}/{fig_name}.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Des routines statistiques\n",
    "\n",
    "Les routines statistiques utilisées dans ce notebook sont regroupés dans cette section :\n",
    "\n",
    "- format des outputs\n",
    "- normalité d'une série\n",
    "- homoscédasticité de groupes pour une série\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_stat_p(stat, p, name=None):\n",
    "    ch = f'{name} : ' if name else ''\n",
    "    ch += f'stat={stat:.3f}, p={p:.3f}'\n",
    "    if p < 0.001:\n",
    "        ch += '***'\n",
    "    elif p < 0.01:\n",
    "        ch += '**'\n",
    "    elif p < 0.05:\n",
    "        ch += '*'\n",
    "    return ch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Des tests de normalité\n",
    "\n",
    "- S'il y a moins de 50 observations, utilise Shapiro test,\n",
    "- Sinon, utilise 'NormalTest' fourni par scipy qui est basé sur D’Agostino et Pearson.\n",
    "\n",
    "Un alternatif est d'utiliser le test de Kolmogorov-Smirnov avec comparaison à la distribution normal ('goodness of fit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro, kstest\n",
    "\n",
    "\n",
    "def test_normality(series: pd.Series, alpha=0.05):\n",
    "    s = series.astype(float).dropna()\n",
    "    if len(s) < 3:\n",
    "        # il faut au moins 3 points\n",
    "        return\n",
    "    if len(s) < 50:\n",
    "        stat, p = shapiro(s)\n",
    "        ch = format_stat_p(stat, p, name=f'Shapiro [{s.name}]')\n",
    "    else:\n",
    "        stat, p = kstest(s, cdf='norm')\n",
    "        ch = format_stat_p(stat, p, name=f'Kolmogorov-Smirnov [{s.name}]')\n",
    "        # stat, p = normaltest(s)\n",
    "        # ch = format_stat_p(stat, p, name=f'NormalTest [{s.name}]')\n",
    "    if p > alpha:\n",
    "        choix = 'accept H0: probablement Gaussian'\n",
    "    else:\n",
    "        choix = 'reject H0: probablement pas Gaussian'\n",
    "    return p, ch, choix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Tests d'égalité de variance des groupes (homoscédasticité)\n",
    "\n",
    "- si les groupes ont toutes une distribution normale, utilise Bartlett (test paramétrique)\n",
    "- sinon, utilise Levene (test non paramétrique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_groups(df: pd.DataFrame, y_var: str, groups_var: str) -> list:\n",
    "    \"\"\"Créer une liste de groupes de y_var pour tests statistiques entre groupes\"\"\"\n",
    "    data = df[[y_var, groups_var]].dropna()\n",
    "    # certain tests n'accepte pas type int\n",
    "    data[y_var] = data[y_var].astype(float)\n",
    "    groups = []\n",
    "    group_names = data[groups_var].unique()\n",
    "    group_names.sort()\n",
    "    for group_name in group_names:\n",
    "        groups.append(data[data[groups_var] == group_name]\n",
    "                      [y_var].rename(group_name))\n",
    "    return groups\n",
    "\n",
    "\n",
    "def get_grp_size(groups: list) -> str:\n",
    "    group_sizes = [len(g) for g in groups]\n",
    "    return f'(n={np.sum(group_sizes)}), {group_sizes}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import bartlett, levene\n",
    "\n",
    "\n",
    "def test_homoscedascity(groups: list, normality=False, alpha=0.05):\n",
    "    print(f'test_homoscedascity groups : {get_grp_size(groups)}')\n",
    "    if normality:\n",
    "        stat, p = bartlett(*groups)\n",
    "        ch = format_stat_p(stat, p, 'Bartlett homoscédasticité')\n",
    "    else:\n",
    "        stat, p = levene(*groups)\n",
    "        ch = format_stat_p(stat, p, 'Levene homoscédasticité')\n",
    "    if p > alpha:\n",
    "        choix = 'accept H0: les groupes ont un écart type similaire'\n",
    "    else:\n",
    "        choix = 'reject H0: les groupes ont des écart types différents'\n",
    "    return p, ch, choix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import et nettoyage des données\n",
    "\n",
    "Les données de consommation sont à télécharger à [cette adresse](https://www.kaggle.com/city-of-seattle/sea-building-energy-benchmarking#2015-building-energy-benchmarking.csv).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Description des données (metadata)\n",
    "\n",
    "- les descriptions des champs sont fournies par les fichiers metadata (format json)\n",
    "- conversion en CSV pour faciliter la lecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 : il y a 47 colonnes\n",
      "2016 : il y a 46 colonnes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def create_data_dict_csv_from_json(file: str, outfile: str) -> pd.DataFrame:\n",
    "    if os.path.exists(outfile):\n",
    "        return pd.read_csv(outfile).iloc[:, -3:]\n",
    "    data = json.loads(open(file, \"r\").read())\n",
    "    df = pd.json_normalize([data], record_path='columns', max_level=0)\n",
    "    df = df[['name', 'dataTypeName', 'description']]\n",
    "    df.to_csv(outfile)\n",
    "    return df\n",
    "\n",
    "\n",
    "meta2015 = 'data/raw/socrata_metadata_2015-building-energy-benchmarking.json'\n",
    "meta2016 = 'data/raw/socrata_metadata_2016-building-energy-benchmarking.json'\n",
    "\n",
    "if not os.path.exists('data/out'):\n",
    "    os.makedirs('data/out')\n",
    "out2015 = 'data/out/datadict2015.csv'\n",
    "out2016 = 'data/out/datadict2016.csv'\n",
    "\n",
    "dict2015 = create_data_dict_csv_from_json(meta2015, out2015)\n",
    "dict2016 = create_data_dict_csv_from_json(meta2016, out2016)\n",
    "print(f'2015 : il y a {len(dict2015)} colonnes')\n",
    "print(f'2016 : il y a {len(dict2016)} colonnes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Les variables cibles (targets) à prédire\n",
    "\n",
    "En regardent les descriptions des champs (les fichiers CSV), on voit que les champs à prédire sont :\n",
    "\n",
    "- `SiteEnergyUse(kBtu)` = **consommation totale d’énergie**\n",
    "- `TotalGHGEmissions` = **les émissions de CO2 (equivalence)**\n",
    "\n",
    "Ces 2 champs sont probablement fortement corrélés avec `PropertyGFABuilding(s)` = le surface totale intérieure du bâtiment : On attend qu'un gros bâtiment aura plus de consommation d'énergie qu'un petit bâtiment, pour la même type d'usage.\n",
    "\n",
    "#### 2.1.1.1 Les variables alternatifs à prédire\n",
    "\n",
    "Sans transformation des residues d'erreur, la modèle risque de mettre trop de poids pour les gros bâtiments. Une façon de réduire le poids des grands bâtiments sera de prédire :\n",
    "\n",
    "- `SiteEUI(kBtu/sf)` = **consommation totale d’énergie** divisé par surface totale intérieure du bâtiment\n",
    "- `GHGEmissionsIntensity` = **les émissions de CO2 (equivalence)** divisé par surface totale intérieure du bâtiment\n",
    "\n",
    "Puis, multiplié ces previsions par la surface totale du bâtiment pour arriver à la prévision de consommation totale d'énergie.\n",
    "\n",
    "On évaluera les effets pendant la modélisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dataTypeName</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SiteEUI(kBtu/sf)</td>\n",
       "      <td>number</td>\n",
       "      <td>Site Energy Use Intensity (EUI) is a property's Site Energy Use divided by its gross floor area. Site Energy Use is the annual amount of all the energy consumed by the property on-site, as reported on utility bills. Site EUI is measured in thousands of British thermal units (kBtu) per square foot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SiteEnergyUse(kBtu)</td>\n",
       "      <td>number</td>\n",
       "      <td>The annual amount of energy consumed by the property from all sources of energy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TotalGHGEmissions</td>\n",
       "      <td>text</td>\n",
       "      <td>The total amount of greenhouse gas emissions, including carbon dioxide, methane, and nitrous oxide gases released into the atmosphere as a result of energy consumption at the property, measured in metric tons of carbon dioxide equivalent. This calculation uses a GHG emissions factor from Seattle CIty Light's portfolio of generating resources. This uses Seattle City Light's 2015 emissions factor of 52.44 lbs CO2e/MWh until the 2016 factor is available. Enwave steam factor = 170.17 lbs CO2e/MMBtu. Gas factor sourced from EPA Portfolio Manager = 53.11 kg CO2e/MBtu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>GHGEmissionsIntensity</td>\n",
       "      <td>text</td>\n",
       "      <td>Total Greenhouse Gas Emissions divided by property's gross floor area, measured in kilograms of carbon dioxide equivalent per square foot. This calculation uses a GHG emissions factor from Seattle City Light's portfolio of generating resources</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name dataTypeName  \\\n",
       "29       SiteEUI(kBtu/sf)       number   \n",
       "33    SiteEnergyUse(kBtu)       number   \n",
       "44      TotalGHGEmissions         text   \n",
       "45  GHGEmissionsIntensity         text   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  description  \n",
       "29                                                                                                                                                                                                                                                                                 Site Energy Use Intensity (EUI) is a property's Site Energy Use divided by its gross floor area. Site Energy Use is the annual amount of all the energy consumed by the property on-site, as reported on utility bills. Site EUI is measured in thousands of British thermal units (kBtu) per square foot.  \n",
       "33                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The annual amount of energy consumed by the property from all sources of energy.  \n",
       "44  The total amount of greenhouse gas emissions, including carbon dioxide, methane, and nitrous oxide gases released into the atmosphere as a result of energy consumption at the property, measured in metric tons of carbon dioxide equivalent. This calculation uses a GHG emissions factor from Seattle CIty Light's portfolio of generating resources. This uses Seattle City Light's 2015 emissions factor of 52.44 lbs CO2e/MWh until the 2016 factor is available. Enwave steam factor = 170.17 lbs CO2e/MMBtu. Gas factor sourced from EPA Portfolio Manager = 53.11 kg CO2e/MBtu.   \n",
       "45                                                                                                                                                                                                                                                                                                                                        Total Greenhouse Gas Emissions divided by property's gross floor area, measured in kilograms of carbon dioxide equivalent per square foot. This calculation uses a GHG emissions factor from Seattle City Light's portfolio of generating resources  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols = ['SiteEnergyUse(kBtu)', 'SiteEUI(kBtu/sf)',\n",
    "               'TotalGHGEmissions', 'GHGEmissionsIntensity']\n",
    "\n",
    "dict2016[dict2016['name'].isin(target_cols)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Est-ce que les données de 2015 et 2016 sont compatibles ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colonnes unique à année 2015 : ['2010 Census Tracts', 'City Council Districts', 'Comment', 'GHGEmissions(MetricTonsCO2e)', 'GHGEmissionsIntensity(kgCO2e/ft2)', 'Location', 'OtherFuelUse(kBtu)', 'SPD Beats', 'Seattle Police Department Micro Community Policing Plan Areas', 'Zip Codes']\n",
      "colonnes unique à année 2016 : ['Address', 'City', 'Comments', 'GHGEmissionsIntensity', 'Latitude', 'Longitude', 'State', 'TotalGHGEmissions', 'ZipCode']\n"
     ]
    }
   ],
   "source": [
    "cols_unique2015 = set(list(dict2015['name'])) - set(list(dict2016['name']))\n",
    "cols_unique2016 = set(list(dict2016['name'])) - set(list(dict2015['name']))\n",
    "print(f'colonnes unique à année 2015 : {sorted(cols_unique2015)}')\n",
    "print(f'colonnes unique à année 2016 : {sorted(cols_unique2016)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analyse Exploratoire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Enregistre les données nettoyées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08f54268de9884c973a82c2c5267bbf1de8fae7577a142dd199c5c3f90c0dd65"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('OC_3': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
